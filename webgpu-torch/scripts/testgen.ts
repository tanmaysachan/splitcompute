import { CodeWriter } from "../src/opgen";
import { OpSpec, ReductionOpSpec } from "../src/op_spec";
import { opKernelSpecs } from "../src/kernels_opgen";

// import fs
import * as fs from "fs";
import { KernelSpec } from "../src/kernel";
import { TensorArrayData } from "../src/storage";

console.log("Running test code generator...");

const unaryTestValues = [
    -2.0, -1.0, -0.5, 0.0, 0.5, 1.0, 2.0
];
const binaryTestValues = [
    -0.5, 0.0, 0.3
];

const absSrcDir = fs.realpathSync(__dirname + "/../src");
console.log("src dir:", absSrcDir);
const pythonTestsPath = `${absSrcDir}/../scripts/testgen_tests.py`;
const pythonTestResultsPath = `${absSrcDir}/../scripts/testgen_tests_results.json`;
const typeScriptTestsName = `ops_opgen.test.ts`;
const typeScriptTestsPath = `${absSrcDir}/${typeScriptTestsName}`;
const indexTestsPath = `${absSrcDir}/index_tests.ts`;

function writePythonTests() {
    const w = new CodeWriter();
    w.writeLine(`# Generated by scripts/testgen.ts`);
    w.writeLine(`# Do not edit this file directly.`);
    w.writeLine(`import torch`);
    w.writeLine(`import json`);
    w.writeLine(`import math`);
    w.writeLine(`results = []`);
    w.writeLine(`def nan_to_str(ar):`);
    w.indent();
    w.writeLine(`ninf = float("-Inf")`);
    w.writeLine(`if ar is None:`);
    w.indent();
    w.writeLine(`return None`);
    w.dedent();
    w.writeLine(`elif isinstance(ar, list):`);
    w.indent();
    w.writeLine(`return [nan_to_str(x) for x in ar]`);
    w.dedent();
    w.writeLine(`else:`);
    w.indent();
    w.writeLine(`x = float(ar)`);
    w.writeLine(`return "NaN" if math.isnan(x) else ("+Inf" if x == float("+Inf") else ("-Inf" if x == ninf else x))`);
    w.dedent();
    w.dedent();
    w.writeLine(`def tensor_to_list(tensor):`);
    w.indent();
    // Check if the tensor is actually just a float first
    w.writeLine(`if isinstance(tensor, float):`);
    w.indent();
    w.writeLine(`return nan_to_str(tensor)`);
    w.dedent();
    w.writeLine(`return nan_to_str(tensor.detach().numpy().tolist())`);
    w.dedent();
    w.writeLine(`def add_results(op_name, kernel_name, inputs, outputs, grads, gradError):`);
    w.indent();
    w.writeLine(`results.append([op_name, kernel_name, [tensor_to_list(x) for x in inputs], [tensor_to_list(x) for x in outputs], [tensor_to_list(x) for x in grads] if grads is not None else None, gradError])`);
    w.dedent();
    function shouldOutputKernelSpec(kernelSpec: KernelSpec): boolean {
        const kernelName = kernelSpec.name;
        const isGrad = kernelName.endsWith("_grad");
        if (isGrad) return false;
        const isScalar = kernelName.includes("_scalar");
        if (isScalar) return false;
        const isStrided = kernelName.includes("_strided");
        if (isStrided) return false;
        if (kernelName == "positive_") return false; // Not in torch
        if (kernelName == "logaddexp_") return false; // Not in torch
        if (kernelName == "logaddexp2_") return false; // Not in torch
        // if (kernelName == "xlogy") return false; // Test values create too much trouble
        return true;
    }
    for (var [opSpec, kernelSpec] of opKernelSpecs) {
        if (!shouldOutputKernelSpec(kernelSpec))
            continue;        
        const opName = opSpec.name;
        const kernelName = kernelSpec.name;
        const isUnary = opSpec.type == "unary";
        const isBinary = opSpec.type == "binary";
        const isReduction = opSpec.type == "reduction";
        const isInplace = kernelName.endsWith("_");
        const hasAlpha = opSpec.alpha ?? false;
        const params = ["input"];
        const args = ["input"];
        if (isBinary) {
            params.push("other");
            args.push("other");
            params.push("scalar");
        }
        // if (hasAlpha) {
        //     params.push("alpha");
        // }
        const paramsS = params.join(", ");
        const argsS = args.join(", ");
        w.writeLine(`def test_${kernelName}_value(${paramsS}):`);
        w.indent();
        w.writeLine(`grads = []`);
        w.writeLine(`gradError = False`);
        if (isInplace) {
            w.writeLine(`input = torch.tensor(input, dtype=torch.float32)`);
            w.writeLine(`output = input.clone()`);
            if (opSpec.torchName && opSpec.torchName.startsWith("torch.nn.functional")) {
                if (isBinary) {
                    w.writeLine(`other = torch.tensor(other, dtype=torch.float32)`);
                    w.writeLine(`${opSpec.torchName}(output, other, inplace=True)`);
                }
                else {
                    w.writeLine(`${opSpec.torchName}(output, inplace=True)`);
                }
            }
            else {
                if (isBinary) {
                    w.writeLine(`other = torch.tensor(other, dtype=torch.float32)`);
                    w.writeLine(`output.${kernelName}(other)`);
                }
                else {
                    w.writeLine(`output.${kernelName}()`);
                }
            }
        }
        else {
            w.writeLine(`input = torch.tensor(input, dtype=torch.float32, requires_grad=True)`);
            if (isBinary) {
                w.writeLine(`other = other[0] if scalar else torch.tensor(other, dtype=torch.float32, requires_grad=True)`);
            }
            const functionName = opSpec.torchName ?? `torch.${kernelName}`;
            w.writeLine(`output = ${functionName}(${argsS})`);
            if (opSpec.backward) {
                w.writeLine(`try:`);
                w.indent();
                w.writeLine(`output.backward()`);
                w.writeLine(`assert input.grad is not None`);
                if (isBinary) {
                    w.writeLine(`grads = [input.grad, 0.0 if scalar else other.grad]`);
                }
                else {
                    w.writeLine(`grads = [input.grad]`);
                }
                w.dedent();
                w.writeLine(`except:`);
                w.indent();
                w.writeLine(`gradError = True`);
                w.dedent();
            }
        }
        w.writeLine(`add_results("${opName}", "${kernelName}", [${args}], [output], grads, gradError)`);
        w.dedent();
        w.writeLine(`def test_${kernelName}():`);
        w.indent();
        if (isUnary) {
            for (const v of unaryTestValues) {
                w.writeLine(`test_${kernelName}_value([${v}])`);
            }
        }
        else if (isBinary) {
            let i = 0;
            for (const v1 of binaryTestValues) {
                for (const v2 of binaryTestValues) {
                    let scalar = (i === 0) && (kernelName !== "atan2" && kernelName !== "hypot" && kernelName !== "ldexp" && kernelName !== "logaddexp" && kernelName !== "logaddexp2");
                    w.writeLine(`test_${kernelName}_value([${v1}], [${v2}], ${scalar?'True':'False'})`);
                    i++;
                }
            }
        }
        else {
            w.writeLine(`pass`);
        }
        w.dedent();
    }
    w.writeLine(`if __name__ == "__main__":`);
    w.indent();
    for (var [opSpec, kernelSpec] of opKernelSpecs) {
        if (!shouldOutputKernelSpec(kernelSpec))
            continue;        
        const kernelName = kernelSpec.name;
        w.writeLine(`test_${kernelName}()`);
    }
    w.writeLine(`with open("${pythonTestResultsPath}", "w") as f:`);
    w.indent();
    w.writeLine(`results_json = json.dumps(results, indent=2)`);
    w.writeLine(`f.write(results_json)`);
    w.dedent();
    w.dedent();
    writeFile(pythonTestsPath, w.toString());
}
writePythonTests();

function runPythonTests() {
    const { spawnSync } = require("child_process");
    const pythonPath = "python3";
    const pythonArgs = [pythonTestsPath];
    const pythonResult = spawnSync(pythonPath, pythonArgs);
    const stdout = pythonResult.stdout.toString();
    const stderr = pythonResult.stderr.toString();
    if (stdout.length > 0) {
        console.log(stdout);
    }
    if (stderr.length > 0) {
        console.error(stderr);
    }
}
runPythonTests();

// Load the results
const pythonTestResults: [string, string, TensorArrayData[], TensorArrayData[], TensorArrayData[]|null, boolean][] = JSON.parse(fs.readFileSync(pythonTestResultsPath, "utf-8"));
console.log("pythonTestResults:", pythonTestResults.length);
const resultsByKernelName:{[name:string]:[TensorArrayData[], TensorArrayData[], TensorArrayData[]|null, boolean][]}= {};
for (const [opName, kernelName, inputs, outputs, grads, gradError] of pythonTestResults) {
    const key = kernelName;
    let results = resultsByKernelName[key];
    if (!results) {
        results = [];
        resultsByKernelName[key] = results;
    }
    results.push([inputs, outputs, grads, gradError]);
}

function writeTypeScriptTestCode() {
    const w = new CodeWriter();
    w.writeLine(`import { runOpgenTestForward as f, runOpgenTestBackward as b } from "./ops_opgen_test_support";`);
    for (var kernelName in resultsByKernelName) {
        const results = resultsByKernelName[kernelName];
        const isInPlace = kernelName.endsWith("_");
        const isStrided = kernelName.includes("_strided");
        if (isStrided) continue;
        for (const r of results) {
            const inputArgs = r[0].map(x => JSON.stringify(x));
            w.writeLine(`test("${kernelName}(${inputArgs.join(", ")})", async () => {`);
            w.indent();
            w.writeLine(`await f("${kernelName}", ${JSON.stringify(r[0])}, ${JSON.stringify(r[1])});`);
            w.dedent();
            w.writeLine(`});`);
            if (!isInPlace) {
                w.writeLine(`test("${kernelName}(${inputArgs.join(", ")}) gradient", async () => {`);
                w.indent();
                w.writeLine(`await b("${kernelName}", ${JSON.stringify(r[0])}, ${JSON.stringify(r[2])}, ${JSON.stringify(r[3])});`);
                w.dedent();
                w.writeLine(`});`);
            }
        }
    }
    writeFile(typeScriptTestsPath, w.toString());
}
writeTypeScriptTestCode();

function writeIndexTests() {
    const w = new CodeWriter();
    w.writeLine(`// This file is auto-generated by testgen.ts
export { hasWebGPU, initWebGPUAsync } from "./webgpu";
export { tensor } from "./ops_artisanal";`);
    // Get all file names from ${absSrcDir}/*.test.ts
    const testFiles = fs.readdirSync(absSrcDir).filter(x => x.endsWith(".test.ts"));
    for (const testFile of testFiles) {
        if (typeScriptTestsPath.endsWith(testFile)) continue;
        w.writeLine(`export * from "./${testFile.slice(0, -3)}";`);
    }
    w.writeLine(`export * from "./${typeScriptTestsName.slice(0, -3)}";`);
    w.writeLine(``);
    writeFile(indexTestsPath, w.toString());
}

function writeFile(path: string, code: string) {
    const oldCode = fs.existsSync(path) ? fs.readFileSync(path, { encoding: "utf8" }) : null;
    if (oldCode === code) {
        console.log("OK", path);
    }
    else {
        console.log("Writing", path);
        fs.writeFileSync(path, code, { encoding: "utf8" });
    }
}

writeIndexTests();
